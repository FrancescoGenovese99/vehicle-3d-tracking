{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8492edc-5bc3-4e3c-ab95-c339353dbb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Import completati\n",
      "  OpenCV: 4.8.1\n",
      "  NumPy: 1.24.3\n",
      "‚úì Directory video trovata: 5 file\n",
      "‚úì Detection functions caricate\n",
      "‚úì Task 1: Homography Solver caricato\n",
      "‚úì PnP Full Solver caricato\n",
      "‚úì BBox 3D Projector caricato\n",
      "‚úì Configurazione veicolo e camera caricata\n",
      "‚úì Vehicle detection caricato\n",
      "‚úì Menu interattivo caricato\n",
      "‚úì Sistema main caricato\n",
      "üìπ Video selezionato: 1.mp4\n",
      "\n",
      "============================================================\n",
      "VEHICLE 3D LOCALIZATION - METODO DI CALCOLO\n",
      "============================================================\n",
      "\n",
      "Scegli il metodo di localizzazione:\n",
      "\n",
      "1. HOMOGRAPHY (Task 1)\n",
      "   - Usa 4 angoli targa (complanari)\n",
      "   - Formula: [r1 r2 t] = K‚Åª¬π H\n",
      "   - Limitazione: scarsa prospettiva\n",
      "\n",
      "2. PNP FULL (Metodo Completo)\n",
      "   - Usa 6+ punti (fari + targa)\n",
      "   - solvePnP con refinement\n",
      "   - Pi√π robusto e accurato\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Inserisci scelta (1-2):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ PROCESSING CON METODO: HOMOGRAPHY\n",
      "üìπ Input: /app/data/videos/input/1.mp4\n",
      "üíæ Output: /app/data/videos/output/1_homography_3d.mp4\n",
      "\n",
      "üìä Info video:\n",
      "   Risoluzione: 1908x1080\n",
      "   FPS: 30.0\n",
      "   Frames totali: 220\n",
      "\n",
      "üîç RICERCA VEICOLO NEL VIDEO...\n",
      "   Scansione primi 300 frames...\n",
      "  Frame 0: pixels rossi=496, confidence=8.02%\n",
      "  Frame 30: pixels rossi=1495, confidence=24.18%\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 53\n",
      "   Confidence: 99.44%, Pixel rossi: 6147\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 54\n",
      "   Confidence: 100.00%, Pixel rossi: 9008\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 55\n",
      "   Confidence: 100.00%, Pixel rossi: 10162\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 56\n",
      "   Confidence: 100.00%, Pixel rossi: 10824\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 57\n",
      "   Confidence: 100.00%, Pixel rossi: 10829\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 58\n",
      "   Confidence: 100.00%, Pixel rossi: 10787\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 59\n",
      "   Confidence: 100.00%, Pixel rossi: 10224\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "  Frame 60: pixels rossi=9761, confidence=100.00%\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 60\n",
      "   Confidence: 100.00%, Pixel rossi: 9761\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 61\n",
      "   Confidence: 100.00%, Pixel rossi: 9681\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 62\n",
      "   Confidence: 100.00%, Pixel rossi: 9575\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 63\n",
      "   Confidence: 100.00%, Pixel rossi: 9000\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 64\n",
      "   Confidence: 100.00%, Pixel rossi: 8839\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 65\n",
      "   Confidence: 100.00%, Pixel rossi: 8842\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 66\n",
      "   Confidence: 100.00%, Pixel rossi: 8935\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 67\n",
      "   Confidence: 100.00%, Pixel rossi: 8777\n",
      "   Detection completa fallita, continuo ricerca...\n",
      "\n",
      "‚úì Possibile veicolo rilevato al frame 68\n",
      "   Confidence: 100.00%, Pixel rossi: 9106\n",
      "‚úÖ VEICOLO CONFERMATO al frame 68!\n",
      "   Fari: 2 rilevati\n",
      "   Angoli targa: 4\n",
      "\n",
      "üìù Scrittura frames iniziali (68 frames)...\n",
      "\n",
      "‚è≥ PROCESSING dal frame 68 al frame 220...\n",
      "  üìç 100/220 (21.1%) - Pose: 0\n",
      "  üìç 150/220 (53.9%) - Pose: 0\n",
      "  üìç 200/220 (86.8%) - Pose: 0\n",
      "\n",
      "============================================================\n",
      "‚úÖ PROCESSING COMPLETATO!\n",
      "============================================================\n",
      "üìä Statistiche:\n",
      "   Frame iniziale veicolo: 68\n",
      "   Frames processati: 152\n",
      "   Frames con posa 3D: 0\n",
      "   Tasso successo: 0.0%\n",
      "\n",
      "üíæ Video salvato: /app/data/videos/output/1_homography_3d.mp4\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# IMPORT E SETUP\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "print(\"‚úì Import completati\")\n",
    "print(f\"  OpenCV: {cv2.__version__}\")\n",
    "print(f\"  NumPy: {np.__version__}\")\n",
    "\n",
    "# Verifica directory\n",
    "VIDEO_DIR = '/app/data/videos/input/'\n",
    "if os.path.exists(VIDEO_DIR):\n",
    "    videos = [f for f in os.listdir(VIDEO_DIR) if f.endswith(('.mp4','.avi','.mov'))]\n",
    "    print(f\"‚úì Directory video trovata: {len(videos)} file\")\n",
    "else:\n",
    "    print(f\"‚ùå Directory non trovata: {VIDEO_DIR}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DETECTION FUNCTIONS\n",
    "# =========================\n",
    "\n",
    "def detect_headlights_and_plate(frame, config, debug_overlay=None):\n",
    "    \"\"\"\n",
    "    Esegue la detection completa di fari e targa.\n",
    "    Restituisce: (success, fari, extremes, plate_corners_global, backup_points, debug_roi)\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    \n",
    "    # DETECTION FARI\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    V = hsv[:,:,2]\n",
    "    \n",
    "    mask = cv2.inRange(V, config['V_LOWER'], 255)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,9))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    contours,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    MIN_AREA = config['MIN_CONTOUR_AREA_RATIO'] * width * height\n",
    "    MAX_Y = int(height * config['MAX_Y_RATIO'])\n",
    "    \n",
    "    candidates = []\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) < MIN_AREA:\n",
    "            continue\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if y > MAX_Y or w/h > 1.0 or h/w < config['MIN_VERTICAL_RATIO']:\n",
    "            continue\n",
    "        M = cv2.moments(c)\n",
    "        if M['m00'] == 0:\n",
    "            continue\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        candidates.append((c,cx,cy))\n",
    "    \n",
    "    if len(candidates) < 2:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    candidates = sorted(candidates, key=lambda p:p[1])\n",
    "    mid = len(candidates)//2\n",
    "    clusters = [candidates[:mid], candidates[mid:]]\n",
    "    \n",
    "    # Centro fari\n",
    "    fari = []\n",
    "    for cluster in clusters:\n",
    "        xs,ys,a = [],[],[]\n",
    "        for c,cx,cy in cluster:\n",
    "            ar = cv2.contourArea(c)\n",
    "            xs.append(cx*ar)\n",
    "            ys.append(cy*ar)\n",
    "            a.append(ar)\n",
    "        fari.append((int(sum(xs)/sum(a)), int(sum(ys)/sum(a))))\n",
    "    \n",
    "    # Punti estremi fari\n",
    "    extremes = {}\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        y_mid = int(np.mean([cy for _,_,cy in cluster]))\n",
    "        pts = []\n",
    "        for c,_,_ in cluster:\n",
    "            for px,py in c[:,0,:]:\n",
    "                if abs(py - y_mid) <= config['Y_TOLERANCE']:\n",
    "                    pts.append((px,py))\n",
    "        if idx == 0:\n",
    "            extremes['SX'] = min(pts, key=lambda p:p[0])\n",
    "        else:\n",
    "            extremes['DX'] = max(pts, key=lambda p:p[0])\n",
    "    \n",
    "    # DETECTION TARGA\n",
    "    fari_bottom_y = []\n",
    "    for cluster in clusters:\n",
    "        ys = []\n",
    "        for c,_,_ in cluster:\n",
    "            ys.extend(c[:,0,1])\n",
    "        fari_bottom_y.append(max(ys))\n",
    "    \n",
    "    y_base = max(fari_bottom_y)\n",
    "    x1 = extremes['SX'][0]\n",
    "    x2 = extremes['DX'][0]\n",
    "    y1 = min(y_base + 20, height-1)\n",
    "    y2 = min(y1 + int(0.18 * height), height)\n",
    "    \n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    if roi.size == 0:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    V_roi = hsv_roi[:,:,2]\n",
    "    \n",
    "    mask_plate = cv2.inRange(V_roi, config['V_PLATE_LOW'], config['V_PLATE_HIGH'])\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,3))\n",
    "    mask_plate = cv2.morphologyEx(mask_plate, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    contours,_ = cv2.findContours(mask_plate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    mask_cluster = np.zeros_like(mask_plate)\n",
    "    cv2.drawContours(mask_cluster, [largest], -1, 255, -1)\n",
    "    \n",
    "    ys, xs = np.where(mask_cluster > 0)\n",
    "    if len(xs) == 0 or len(ys) == 0:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    x_min, x_max = xs.min(), xs.max()\n",
    "    y_min, y_max = ys.min(), ys.max()\n",
    "    \n",
    "    pad_x = int(0.25 * (x_max - x_min))\n",
    "    pad_y = int(0.40 * (y_max - y_min))\n",
    "    \n",
    "    roi_x_min = max(0, x_min - pad_x)\n",
    "    roi_x_max = min(roi.shape[1], x_max + pad_x)\n",
    "    roi_y_min = max(0, y_min - pad_y)\n",
    "    roi_y_max = min(roi.shape[0], y_max + pad_y)\n",
    "    \n",
    "    roi_plate = roi[roi_y_min:roi_y_max, roi_x_min:roi_x_max]\n",
    "    \n",
    "    if roi_plate.size == 0:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    # Pre-processing\n",
    "    gray_plate = cv2.cvtColor(roi_plate, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    gray_plate = clahe.apply(gray_plate)\n",
    "    gray_plate = cv2.GaussianBlur(gray_plate, (7,7), 0)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    gradient = cv2.morphologyEx(gray_plate, cv2.MORPH_GRADIENT, kernel)\n",
    "    \n",
    "    _, gradient_binary = cv2.threshold(gradient, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Usa minAreaRect come fallback robusto\n",
    "    contours_grad, _ = cv2.findContours(gradient_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours_grad:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    main_contour = max(contours_grad, key=cv2.contourArea)\n",
    "    \n",
    "    # minAreaRect (pi√π robusto)\n",
    "    rect = cv2.minAreaRect(main_contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int32(box)\n",
    "    \n",
    "    # Ordina punti (TL, TR, BR, BL)\n",
    "    pts = box.reshape(4,2)\n",
    "    s = pts.sum(axis=1)\n",
    "    \n",
    "    TL = tuple(pts[np.argmin(s)])\n",
    "    BR = tuple(pts[np.argmax(s)])\n",
    "    \n",
    "    remaining_idx = [i for i in range(4) if i not in [np.argmin(s), np.argmax(s)]]\n",
    "    if pts[remaining_idx[0]][0] > pts[remaining_idx[1]][0]:\n",
    "        TR = tuple(pts[remaining_idx[0]])\n",
    "        BL = tuple(pts[remaining_idx[1]])\n",
    "    else:\n",
    "        TR = tuple(pts[remaining_idx[1]])\n",
    "        BL = tuple(pts[remaining_idx[0]])\n",
    "    \n",
    "    plate_corners_roi = {'TL':TL,'TR':TR,'BL':BL,'BR':BR}\n",
    "    \n",
    "    # Converti in coordinate globali\n",
    "    plate_corners_global = {}\n",
    "    for k,(px,py) in plate_corners_roi.items():\n",
    "        plate_corners_global[k] = (px + roi_x_min + x1, py + roi_y_min + y1)\n",
    "    \n",
    "    # Backup points (centri lati)\n",
    "    backup_points = []\n",
    "    \n",
    "    debug_roi = None\n",
    "    \n",
    "    return True, fari, extremes, plate_corners_global, backup_points, debug_roi\n",
    "\n",
    "\n",
    "print(\"‚úì Detection functions caricate\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TASK 1: HOMOGRAPHY SOLVER\n",
    "# =========================\n",
    "\n",
    "def solve_with_homography(plate_corners, camera_matrix, vehicle_config):\n",
    "    \"\"\"\n",
    "    Task 1: Localizzazione usando omografia da 4 punti complanari (targa).\n",
    "    Formula: [r1 r2 t] = K‚Åª¬π H\n",
    "    \n",
    "    Args:\n",
    "        plate_corners: dict {'TL': (x,y), 'TR': (x,y), 'BL': (x,y), 'BR': (x,y)}\n",
    "        camera_matrix: matrice K (3x3)\n",
    "        vehicle_config: configurazione veicolo (coordinate 3D targa)\n",
    "    \n",
    "    Returns:\n",
    "        (rvec, tvec, method_info)\n",
    "    \"\"\"\n",
    "    # Punti 2D (immagine)\n",
    "    image_points = np.array([\n",
    "        plate_corners['TL'],\n",
    "        plate_corners['TR'],\n",
    "        plate_corners['BR'],\n",
    "        plate_corners['BL']\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Punti 3D (targa nel sistema del veicolo)\n",
    "    plate_3d = vehicle_config['license_plate_rear_corners']\n",
    "    object_points = np.array([\n",
    "        plate_3d['top_left'][:2],\n",
    "        plate_3d['top_right'][:2],\n",
    "        plate_3d['bottom_right'][:2],\n",
    "        plate_3d['bottom_left'][:2]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Calcola omografia H\n",
    "    H, status = cv2.findHomography(object_points, image_points, method=0)\n",
    "    \n",
    "    if H is None:\n",
    "        return None, None, {'error': 'Homography calculation failed'}\n",
    "    \n",
    "    # Decomposizione: [r1 r2 t] = K‚Åª¬π H\n",
    "    K_inv = np.linalg.inv(camera_matrix)\n",
    "    H_norm = K_inv @ H\n",
    "    \n",
    "    # Normalizzazione\n",
    "    lambda_ = (np.linalg.norm(H_norm[:, 0]) + np.linalg.norm(H_norm[:, 1])) / 2\n",
    "    H_norm = H_norm / lambda_\n",
    "    \n",
    "    # Estrai colonne\n",
    "    r1 = H_norm[:, 0]\n",
    "    r2 = H_norm[:, 1]\n",
    "    t = H_norm[:, 2]\n",
    "    \n",
    "    # Calcola r3 (perpendicolare al piano)\n",
    "    r3 = np.cross(r1, r2)\n",
    "    \n",
    "    # Costruisci matrice di rotazione\n",
    "    R = np.column_stack([r1, r2, r3])\n",
    "    \n",
    "    # Forza ortogonalit√† (SVD)\n",
    "    U, _, Vt = np.linalg.svd(R)\n",
    "    R = U @ Vt\n",
    "    \n",
    "    # Converti a Rodrigues\n",
    "    rvec, _ = cv2.Rodrigues(R)\n",
    "    tvec = t.reshape(3, 1)\n",
    "    \n",
    "    method_info = {\n",
    "        'name': 'Homography',\n",
    "        'points_used': 4,\n",
    "        'type': 'coplanar',\n",
    "        'lambda': float(lambda_)\n",
    "    }\n",
    "    \n",
    "    return rvec, tvec, method_info\n",
    "\n",
    "\n",
    "print(\"‚úì Task 1: Homography Solver caricato\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PNP FULL SOLVER (6+ punti)\n",
    "# =========================\n",
    "\n",
    "def solve_with_pnp_full(fari, plate_corners, camera_matrix, dist_coeffs, vehicle_config):\n",
    "    \"\"\"\n",
    "    Metodo completo con solvePnP usando tutti i punti disponibili.\n",
    "    \n",
    "    Args:\n",
    "        fari: [(x1,y1), (x2,y2)] centri fari\n",
    "        plate_corners: dict con 4 angoli targa\n",
    "        camera_matrix: K\n",
    "        dist_coeffs: coefficienti distorsione\n",
    "        vehicle_config: modello 3D veicolo\n",
    "    \n",
    "    Returns:\n",
    "        (rvec, tvec, method_info)\n",
    "    \"\"\"\n",
    "    # Punti 2D\n",
    "    image_points = []\n",
    "    object_points = []\n",
    "    \n",
    "    # Fari\n",
    "    tail_lights_3d = vehicle_config['tail_lights']\n",
    "    image_points.extend([fari[0], fari[1]])\n",
    "    object_points.extend([\n",
    "        tail_lights_3d['left'],\n",
    "        tail_lights_3d['right']\n",
    "    ])\n",
    "    \n",
    "    # Angoli targa\n",
    "    plate_3d = vehicle_config['license_plate_rear_corners']\n",
    "    for corner_2d_name, corner_3d_name in [\n",
    "        ('TL', 'top_left'), ('TR', 'top_right'), \n",
    "        ('BL', 'bottom_left'), ('BR', 'bottom_right')\n",
    "    ]:\n",
    "        if corner_2d_name in plate_corners:\n",
    "            image_points.append(plate_corners[corner_2d_name])\n",
    "            object_points.append(plate_3d[corner_3d_name])\n",
    "    \n",
    "    image_points = np.array(image_points, dtype=np.float32)\n",
    "    object_points = np.array(object_points, dtype=np.float32)\n",
    "    \n",
    "    # solvePnP\n",
    "    success, rvec, tvec = cv2.solvePnP(\n",
    "        object_points, \n",
    "        image_points, \n",
    "        camera_matrix, \n",
    "        dist_coeffs,\n",
    "        flags=cv2.SOLVEPNP_ITERATIVE\n",
    "    )\n",
    "    \n",
    "    if not success:\n",
    "        return None, None, {'error': 'PnP failed'}\n",
    "    \n",
    "    # Refine\n",
    "    rvec, tvec = cv2.solvePnPRefineLM(\n",
    "        object_points, \n",
    "        image_points, \n",
    "        camera_matrix, \n",
    "        dist_coeffs, \n",
    "        rvec, \n",
    "        tvec\n",
    "    )\n",
    "    \n",
    "    # Calcola errore di riproiezione\n",
    "    projected, _ = cv2.projectPoints(object_points, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "    projected = projected.reshape(-1, 2)\n",
    "    error = np.linalg.norm(image_points - projected, axis=1).mean()\n",
    "    \n",
    "    method_info = {\n",
    "        'name': 'PnP Full',\n",
    "        'points_used': len(image_points),\n",
    "        'type': 'over-determined',\n",
    "        'reprojection_error': float(error)\n",
    "    }\n",
    "    \n",
    "    return rvec, tvec, method_info\n",
    "\n",
    "\n",
    "print(\"‚úì PnP Full Solver caricato\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# BBOX 3D PROJECTOR\n",
    "# =========================\n",
    "\n",
    "def project_vehicle_bbox(rvec, tvec, camera_matrix, dist_coeffs, vehicle_config):\n",
    "    \"\"\"\n",
    "    Proietta la bounding box 3D del veicolo.\n",
    "    \n",
    "    Returns:\n",
    "        vertices_2d: array (8, 2) con vertici proiettati\n",
    "    \"\"\"\n",
    "    # Dimensioni veicolo\n",
    "    dims = vehicle_config['dimensions']\n",
    "    L = dims['length']\n",
    "    W = dims['width']\n",
    "    H = dims['height']\n",
    "    \n",
    "    # 8 vertici della bbox (origine: centro asse posteriore a suolo)\n",
    "    vertices_3d = np.array([\n",
    "        # Base (z=0)\n",
    "        [0, -W/2, 0],\n",
    "        [0, W/2, 0],\n",
    "        [L, W/2, 0],\n",
    "        [L, -W/2, 0],\n",
    "        # Top (z=H)\n",
    "        [0, -W/2, H],\n",
    "        [0, W/2, H],\n",
    "        [L, W/2, H],\n",
    "        [L, -W/2, H]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Proietta\n",
    "    vertices_2d, _ = cv2.projectPoints(vertices_3d, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "    return vertices_2d.reshape(-1, 2).astype(int)\n",
    "\n",
    "\n",
    "def draw_bbox_3d(frame, vertices_2d, color=(0, 255, 0), thickness=2):\n",
    "    \"\"\"\n",
    "    Disegna la bbox 3D sul frame.\n",
    "    \"\"\"\n",
    "    frame_copy = frame.copy()\n",
    "    \n",
    "    # Edges base (0-1-2-3-0)\n",
    "    base_edges = [(0,1), (1,2), (2,3), (3,0)]\n",
    "    for i, j in base_edges:\n",
    "        cv2.line(frame_copy, tuple(vertices_2d[i]), tuple(vertices_2d[j]), color, thickness)\n",
    "    \n",
    "    # Edges top (4-5-6-7-4)\n",
    "    top_edges = [(4,5), (5,6), (6,7), (7,4)]\n",
    "    for i, j in top_edges:\n",
    "        cv2.line(frame_copy, tuple(vertices_2d[i]), tuple(vertices_2d[j]), color, thickness)\n",
    "    \n",
    "    # Vertical edges (0-4, 1-5, 2-6, 3-7)\n",
    "    for i in range(4):\n",
    "        cv2.line(frame_copy, tuple(vertices_2d[i]), tuple(vertices_2d[i+4]), color, thickness)\n",
    "    \n",
    "    # Evidenzia posteriore (rosso)\n",
    "    cv2.line(frame_copy, tuple(vertices_2d[0]), tuple(vertices_2d[1]), (0, 0, 255), thickness+1)\n",
    "    cv2.line(frame_copy, tuple(vertices_2d[4]), tuple(vertices_2d[5]), (0, 0, 255), thickness+1)\n",
    "    \n",
    "    return frame_copy\n",
    "\n",
    "\n",
    "print(\"‚úì BBox 3D Projector caricato\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# VEHICLE CONFIGURATION\n",
    "# =========================\n",
    "\n",
    "VEHICLE_CONFIG = {\n",
    "    'dimensions': {\n",
    "        'length': 3.70,\n",
    "        'width': 1.74,\n",
    "        'height': 1.525\n",
    "    },\n",
    "    'tail_lights': {\n",
    "        'left': np.array([-0.27, 0.70, 0.50]),\n",
    "        'right': np.array([-0.27, -0.70, 0.50])\n",
    "    },\n",
    "    'license_plate_rear_corners': {\n",
    "        'top_left': np.array([0.0, 0.26, 0.455]),\n",
    "        'top_right': np.array([0.0, -0.26, 0.455]),\n",
    "        'bottom_left': np.array([0.0, 0.26, 0.345]),\n",
    "        'bottom_right': np.array([0.0, -0.26, 0.345])\n",
    "    }\n",
    "}\n",
    "\n",
    "# Camera\n",
    "CAMERA_MATRIX = np.array([\n",
    "    [800.0, 0, 640.0],\n",
    "    [0, 800.0, 360.0],\n",
    "    [0, 0, 1]\n",
    "], dtype=np.float64)\n",
    "\n",
    "DIST_COEFFS = np.zeros(5, dtype=np.float64)\n",
    "\n",
    "print(\"‚úì Configurazione veicolo e camera caricata\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# VEHICLE DETECTION\n",
    "# =========================\n",
    "\n",
    "def detect_vehicle_presence(frame, config, min_red_area_ratio=0.001):\n",
    "    \"\"\"\n",
    "    Verifica se c'√® un veicolo nel frame controllando la presenza di luci rosse.\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    total_pixels = width * height\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    V = hsv[:, :, 2]\n",
    "    \n",
    "    mask_bright = cv2.inRange(V, config['V_LOWER'], 255)\n",
    "    \n",
    "    bright_pixels = np.sum(mask_bright > 0)\n",
    "    bright_ratio = bright_pixels / total_pixels\n",
    "    \n",
    "    min_pixels = int(total_pixels * min_red_area_ratio)\n",
    "    is_present = bright_pixels > min_pixels\n",
    "    \n",
    "    confidence = min(bright_ratio / (min_red_area_ratio * 3), 1.0)\n",
    "    \n",
    "    return is_present, bright_pixels, confidence\n",
    "\n",
    "\n",
    "def wait_for_vehicle(cap, config, max_frames_to_check=300, visualize=True):\n",
    "    \"\"\"\n",
    "    Scansiona il video fino a trovare il veicolo.\n",
    "    \"\"\"\n",
    "    print(\"\\nüîç RICERCA VEICOLO NEL VIDEO...\")\n",
    "    print(f\"   Scansione primi {max_frames_to_check} frames...\")\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    for frame_idx in range(max_frames_to_check):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        is_present, red_pixels, confidence = detect_vehicle_presence(frame, config)\n",
    "        \n",
    "        if visualize and frame_idx % 30 == 0:\n",
    "            print(f\"  Frame {frame_idx}: pixels rossi={red_pixels}, confidence={confidence:.2%}\")\n",
    "        \n",
    "        if is_present and confidence > 0.3:\n",
    "            print(f\"\\n‚úì Possibile veicolo rilevato al frame {frame_idx}\")\n",
    "            print(f\"   Confidence: {confidence:.2%}, Pixel rossi: {red_pixels}\")\n",
    "            \n",
    "            success, fari, extremes, plate_corners, backup_points, _ = detect_headlights_and_plate(frame, config)\n",
    "            \n",
    "            if success:\n",
    "                print(f\"‚úÖ VEICOLO CONFERMATO al frame {frame_idx}!\")\n",
    "                print(f\"   Fari: {len(fari)} rilevati\")\n",
    "                print(f\"   Angoli targa: {len(plate_corners)}\")\n",
    "                \n",
    "                detection_data = {\n",
    "                    'fari': fari,\n",
    "                    'extremes': extremes,\n",
    "                    'plate_corners': plate_corners,\n",
    "                    'backup_points': backup_points\n",
    "                }\n",
    "                \n",
    "                return frame_idx, frame, detection_data\n",
    "            else:\n",
    "                print(f\"   Detection completa fallita, continuo ricerca...\")\n",
    "    \n",
    "    print(f\"\\n‚ùå Nessun veicolo trovato nei primi {max_frames_to_check} frames\")\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "print(\"‚úì Vehicle detection caricato\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MENU INTERATTIVO\n",
    "# =========================\n",
    "\n",
    "def show_method_menu():\n",
    "    \"\"\"\n",
    "    Mostra menu di selezione metodo e restituisce la scelta.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VEHICLE 3D LOCALIZATION - METODO DI CALCOLO\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nScegli il metodo di localizzazione:\\n\")\n",
    "    \n",
    "    print(\"1. HOMOGRAPHY (Task 1)\")\n",
    "    print(\"   - Usa 4 angoli targa (complanari)\")\n",
    "    print(\"   - Formula: [r1 r2 t] = K‚Åª¬π H\")\n",
    "    print(\"   - Limitazione: scarsa prospettiva\\n\")\n",
    "    \n",
    "    print(\"2. PNP FULL (Metodo Completo)\")\n",
    "    print(\"   - Usa 6+ punti (fari + targa)\")\n",
    "    print(\"   - solvePnP con refinement\")\n",
    "    print(\"   - Pi√π robusto e accurato\\n\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"\\nInserisci scelta (1-2): \"))\n",
    "            if choice in [1, 2]:\n",
    "                return choice\n",
    "            else:\n",
    "                print(\"‚ùå Scelta non valida. Riprova.\")\n",
    "        except ValueError:\n",
    "            print(\"‚ùå Inserisci un numero (1 o 2).\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\n‚ö†Ô∏è Operazione annullata.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "print(\"‚úì Menu interattivo caricato\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN SYSTEM\n",
    "# =========================\n",
    "\n",
    "def process_video_with_method(video_path, method_choice, config):\n",
    "    \"\"\"\n",
    "    Processa video con il metodo scelto.\n",
    "    \"\"\"\n",
    "    method_names = {\n",
    "        1: 'homography',\n",
    "        2: 'pnp_full'\n",
    "    }\n",
    "    method_name = method_names[method_choice]\n",
    "    \n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    output_path = os.path.join(\n",
    "        os.path.dirname(video_path).replace('input', 'output'),\n",
    "        f\"{video_name}_{method_name}_3d.mp4\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüé¨ PROCESSING CON METODO: {method_name.upper()}\")\n",
    "    print(f\"üìπ Input: {video_path}\")\n",
    "    print(f\"üíæ Output: {output_path}\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"\\nüìä Info video:\")\n",
    "    print(f\"   Risoluzione: {width}x{height}\")\n",
    "    print(f\"   FPS: {fps}\")\n",
    "    print(f\"   Frames totali: {total_frames}\")\n",
    "    \n",
    "    start_frame, first_frame, detection_data = wait_for_vehicle(cap, config, max_frames_to_check=300)\n",
    "    \n",
    "    if start_frame is None:\n",
    "        print(\"\\n‚ùå ERRORE: Veicolo non rilevato nel video!\")\n",
    "        cap.release()\n",
    "        return\n",
    "    \n",
    "    fari = detection_data['fari']\n",
    "    extremes = detection_data['extremes']\n",
    "    plate_corners = detection_data['plate_corners']\n",
    "    backup_points = detection_data['backup_points']\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\"\\nüìù Scrittura frames iniziali ({start_frame} frames)...\")\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    for i in range(start_frame):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        overlay = frame.copy()\n",
    "        cv2.putText(overlay, f\"Frame: {i}/{total_frames}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "        cv2.putText(overlay, \"WAITING FOR VEHICLE...\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "        out.write(overlay)\n",
    "    \n",
    "    print(f\"\\n‚è≥ PROCESSING dal frame {start_frame} al frame {total_frames}...\")\n",
    "    \n",
    "    prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    tracked_points = {\n",
    "        'faro_sx': np.array([fari[0]], dtype=np.float32),\n",
    "        'faro_dx': np.array([fari[1]], dtype=np.float32),\n",
    "    }\n",
    "    for corner, pt in plate_corners.items():\n",
    "        tracked_points[f'plate_{corner}'] = np.array([pt], dtype=np.float32)\n",
    "    \n",
    "    lk_params = dict(winSize=(21, 21), maxLevel=3,\n",
    "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "    \n",
    "    frames_processed = start_frame\n",
    "    frames_with_pose = 0\n",
    "    redetection_interval = 30\n",
    "    frames_since_redetection = 0\n",
    "    \n",
    "    while frames_processed < total_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        overlay = frame.copy()\n",
    "        curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # TRACKING\n",
    "        new_tracked = {}\n",
    "        for name, pts in tracked_points.items():\n",
    "            new_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, pts, None, **lk_params)\n",
    "            if status[0][0] == 1:\n",
    "                new_tracked[name] = new_pts\n",
    "        \n",
    "        tracked_points = new_tracked\n",
    "        \n",
    "        fari = []\n",
    "        plate_corners = {}\n",
    "        \n",
    "        if 'faro_sx' in tracked_points:\n",
    "            fari.append(tuple(tracked_points['faro_sx'][0].astype(int)))\n",
    "        if 'faro_dx' in tracked_points:\n",
    "            fari.append(tuple(tracked_points['faro_dx'][0].astype(int)))\n",
    "        \n",
    "        for corner in ['TL', 'TR', 'BL', 'BR']:\n",
    "            key = f'plate_{corner}'\n",
    "            if key in tracked_points:\n",
    "                plate_corners[corner] = tuple(tracked_points[key][0].astype(int))\n",
    "        \n",
    "        # RE-DETECTION\n",
    "        frames_since_redetection += 1\n",
    "        if frames_since_redetection >= redetection_interval:\n",
    "            success, new_fari, new_extremes, new_plate, new_backup, _ = detect_headlights_and_plate(frame, config)\n",
    "            if success:\n",
    "                fari = new_fari\n",
    "                plate_corners = new_plate\n",
    "                tracked_points = {\n",
    "                    'faro_sx': np.array([fari[0]], dtype=np.float32),\n",
    "                    'faro_dx': np.array([fari[1]], dtype=np.float32),\n",
    "                }\n",
    "                for corner, pt in plate_corners.items():\n",
    "                    tracked_points[f'plate_{corner}'] = np.array([pt], dtype=np.float32)\n",
    "                \n",
    "                frames_since_redetection = 0\n",
    "                cv2.putText(overlay, \"RE-DETECTION OK\", (10, 90),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        \n",
    "        # CALCOLA POSA (con gestione errori robusta)\n",
    "        rvec, tvec, method_info = None, None, {'name': 'N/A', 'status': 'No detection'}\n",
    "        \n",
    "        try:\n",
    "            if method_choice == 1:\n",
    "                if len(plate_corners) == 4:\n",
    "                    rvec, tvec, method_info = solve_with_homography(\n",
    "                        plate_corners, CAMERA_MATRIX, VEHICLE_CONFIG\n",
    "                    )\n",
    "                    if rvec is None:\n",
    "                        method_info = {'name': 'Homography', 'status': 'Failed'}\n",
    "            \n",
    "            elif method_choice == 2:\n",
    "                if len(fari) == 2 and len(plate_corners) >= 3:\n",
    "                    rvec, tvec, method_info = solve_with_pnp_full(\n",
    "                        fari, plate_corners, CAMERA_MATRIX, DIST_COEFFS, VEHICLE_CONFIG\n",
    "                    )\n",
    "                    if rvec is None:\n",
    "                        method_info = {'name': 'PnP Full', 'status': 'Failed'}\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Errore calcolo posa frame {frames_processed}: {e}\")\n",
    "            rvec, tvec = None, None\n",
    "            method_info = {'name': 'Error', 'status': str(e)[:30]}\n",
    "        \n",
    "        # VISUALIZZA BBOX 3D\n",
    "        if rvec is not None and tvec is not None:\n",
    "            try:\n",
    "                vertices_2d = project_vehicle_bbox(rvec, tvec, CAMERA_MATRIX, DIST_COEFFS, VEHICLE_CONFIG)\n",
    "                overlay = draw_bbox_3d(overlay, vertices_2d)\n",
    "                frames_with_pose += 1\n",
    "                \n",
    "                distance = np.linalg.norm(tvec)\n",
    "                cv2.putText(overlay, f\"Distance: {distance:.2f}m\", (10, height - 60),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Errore proiezione bbox frame {frames_processed}: {e}\")\n",
    "        \n",
    "        # VISUALIZZA PUNTI\n",
    "        for i, pt in enumerate(fari):\n",
    "            cv2.circle(overlay, pt, 8, (0, 255, 255), -1)\n",
    "            cv2.putText(overlay, 'L' if i == 0 else 'R', (pt[0]+10, pt[1]),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        \n",
    "        if len(plate_corners) == 4:\n",
    "            poly = np.array([\n",
    "                plate_corners['TL'], plate_corners['TR'],\n",
    "                plate_corners['BR'], plate_corners['BL']\n",
    "            ], dtype=np.int32)\n",
    "            cv2.polylines(overlay, [poly], True, (0, 255, 0), 2)\n",
    "        \n",
    "        # INFO\n",
    "        cv2.putText(overlay, f\"Frame: {frames_processed}/{total_frames}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        method_name = method_info.get('name', 'N/A') if method_info else 'N/A'\n",
    "        cv2.putText(overlay, f\"Method: {method_name}\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        next_redetect = redetection_interval - frames_since_redetection\n",
    "        color = (0, 255, 255) if next_redetect <= 3 else (200, 200, 200)\n",
    "        cv2.putText(overlay, f\"Next detect: {next_redetect}\", (10, height - 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        out.write(overlay)\n",
    "        frames_processed += 1\n",
    "        prev_gray = curr_gray.copy()\n",
    "        \n",
    "        if frames_processed % 50 == 0:\n",
    "            progress = (frames_processed - start_frame) / (total_frames - start_frame) * 100\n",
    "            print(f\"  üìç {frames_processed}/{total_frames} ({progress:.1f}%) - Pose: {frames_with_pose}\")\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"‚úÖ PROCESSING COMPLETATO!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"üìä Statistiche:\")\n",
    "    print(f\"   Frame iniziale veicolo: {start_frame}\")\n",
    "    print(f\"   Frames processati: {frames_processed - start_frame}\")\n",
    "    print(f\"   Frames con posa 3D: {frames_with_pose}\")\n",
    "    if frames_processed > start_frame:\n",
    "        success_rate = frames_with_pose / (frames_processed - start_frame) * 100\n",
    "        print(f\"   Tasso successo: {success_rate:.1f}%\")\n",
    "    print(f\"\\nüíæ Video salvato: {output_path}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "\n",
    "print(\"‚úì Sistema main caricato\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ESECUZIONE\n",
    "# =========================\n",
    "\n",
    "config = {\n",
    "    'V_LOWER': 210,\n",
    "    'MAX_Y_RATIO': 0.80,\n",
    "    'MIN_VERTICAL_RATIO': 1.2,\n",
    "    'MIN_CONTOUR_AREA_RATIO': 0.00015,\n",
    "    'Y_TOLERANCE': 5,\n",
    "    'V_PLATE_LOW': 150,\n",
    "    'V_PLATE_HIGH': 240,\n",
    "}\n",
    "\n",
    "VIDEO_DIR = '/app/data/videos/input/'\n",
    "OUTPUT_DIR = '/app/data/videos/output/'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "videos = [f for f in os.listdir(VIDEO_DIR) if f.endswith(('.mp4','.avi','.mov'))]\n",
    "\n",
    "if not videos:\n",
    "    print(\"‚ùå Nessun video trovato!\")\n",
    "else:\n",
    "    VIDEO_PATH = os.path.join(VIDEO_DIR, videos[0])\n",
    "    print(f\"üìπ Video selezionato: {videos[0]}\")\n",
    "    \n",
    "    method_choice = show_method_menu()\n",
    "    \n",
    "    if method_choice is not None:\n",
    "        process_video_with_method(VIDEO_PATH, method_choice, config)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nessun metodo selezionato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242fb5ed-8895-4dd5-b3af-00c4baf6bb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
