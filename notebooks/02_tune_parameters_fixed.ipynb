{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Tuning Parametri HSV\n",
    "\n",
    "Notebook interattivo per ottimizzare i parametri di detection HSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carica Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_PATH = '../data/videos/input/video1.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    print(f\"Frame caricato: {frame.shape}\")\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "else:\n",
    "    print(\"Errore caricamento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizza Canali HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Originale (RGB)')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(hsv_frame[:,:,0], cmap='hsv')\n",
    "axes[0, 1].set_title('Hue (H)')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(hsv_frame[:,:,1], cmap='gray')\n",
    "axes[1, 0].set_title('Saturation (S)')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(hsv_frame[:,:,2], cmap='gray')\n",
    "axes[1, 1].set_title('Value (V)')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatistiche HSV:\")\n",
    "print(f\"  H range: [{hsv_frame[:,:,0].min()}, {hsv_frame[:,:,0].max()}]\")\n",
    "print(f\"  S range: [{hsv_frame[:,:,1].min()}, {hsv_frame[:,:,1].max()}]\")\n",
    "print(f\"  V range: [{hsv_frame[:,:,2].min()}, {hsv_frame[:,:,2].max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tuning Interattivo Range Rosso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Import completati\n",
      "  OpenCV: 4.8.1\n",
      "  NumPy: 1.24.3\n",
      "‚úì Directory video trovata: 6 file\n",
      "‚úì Detection functions caricate\n",
      "‚úì Task 1: Homography Solver caricato\n",
      "‚úì PnP Full Solver caricato\n",
      "‚úì BBox 3D Projector caricato\n",
      "‚úì Configurazione veicolo e camera caricata\n",
      "‚úì Sistema main con auto-trigger caricato\n",
      "üìπ Video selezionato: 1.mp4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'show_method_menu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 871\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìπ Video selezionato: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideos[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# MENU INTERATTIVO\u001b[39;00m\n\u001b[0;32m--> 871\u001b[0m method_choice \u001b[38;5;241m=\u001b[39m \u001b[43mshow_method_menu\u001b[49m()\n\u001b[1;32m    873\u001b[0m \u001b[38;5;66;03m# PROCESSA\u001b[39;00m\n\u001b[1;32m    874\u001b[0m process_video_with_method(VIDEO_PATH, method_choice, config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'show_method_menu' is not defined"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# IMPORT E SETUP\n",
    "# =========================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "print(\"‚úì Import completati\")\n",
    "print(f\"  OpenCV: {cv2.__version__}\")\n",
    "print(f\"  NumPy: {np.__version__}\")\n",
    "\n",
    "# Verifica directory\n",
    "VIDEO_DIR = '/app/data/videos/input/'\n",
    "if os.path.exists(VIDEO_DIR):\n",
    "    videos = [f for f in os.listdir(VIDEO_DIR) if f.endswith(('.mp4','.avi','.mov'))]\n",
    "    print(f\"‚úì Directory video trovata: {len(videos)} file\")\n",
    "else:\n",
    "    print(f\"‚ùå Directory non trovata: {VIDEO_DIR}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DETECTION FUNCTIONS\n",
    "# =========================\n",
    "\n",
    "def detect_headlights_and_plate(frame, config, debug_overlay=None):\n",
    "    \"\"\"\n",
    "    Esegue la detection completa di fari e targa.\n",
    "    Restituisce: (success, fari, extremes, plate_corners_global, backup_points, debug_roi)\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    \n",
    "    # DETECTION FARI\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    V = hsv[:,:,2]\n",
    "    \n",
    "    mask = cv2.inRange(V, config['V_LOWER'], 255)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,9))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    contours,_ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    MIN_AREA = config['MIN_CONTOUR_AREA_RATIO'] * width * height\n",
    "    MAX_Y = int(height * config['MAX_Y_RATIO'])\n",
    "    \n",
    "    candidates = []\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) < MIN_AREA:\n",
    "            continue\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if y > MAX_Y or w/h > 1.0 or h/w < config['MIN_VERTICAL_RATIO']:\n",
    "            continue\n",
    "        M = cv2.moments(c)\n",
    "        if M['m00'] == 0:\n",
    "            continue\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        candidates.append((c,cx,cy))\n",
    "    \n",
    "    if len(candidates) < 2:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    candidates = sorted(candidates, key=lambda p:p[1])\n",
    "    mid = len(candidates)//2\n",
    "    clusters = [candidates[:mid], candidates[mid:]]\n",
    "    \n",
    "    # Centro fari\n",
    "    fari = []\n",
    "    for cluster in clusters:\n",
    "        xs,ys,a = [],[],[]\n",
    "        for c,cx,cy in cluster:\n",
    "            ar = cv2.contourArea(c)\n",
    "            xs.append(cx*ar)\n",
    "            ys.append(cy*ar)\n",
    "            a.append(ar)\n",
    "        fari.append((int(sum(xs)/sum(a)), int(sum(ys)/sum(a))))\n",
    "    \n",
    "    # Punti estremi fari\n",
    "    extremes = {}\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        y_mid = int(np.mean([cy for _,_,cy in cluster]))\n",
    "        pts = []\n",
    "        for c,_,_ in cluster:\n",
    "            for px,py in c[:,0,:]:\n",
    "                if abs(py - y_mid) <= config['Y_TOLERANCE']:\n",
    "                    pts.append((px,py))\n",
    "        if idx == 0:\n",
    "            extremes['SX'] = min(pts, key=lambda p:p[0])\n",
    "        else:\n",
    "            extremes['DX'] = max(pts, key=lambda p:p[0])\n",
    "    \n",
    "    # DETECTION TARGA\n",
    "    fari_bottom_y = []\n",
    "    for cluster in clusters:\n",
    "        ys = []\n",
    "        for c,_,_ in cluster:\n",
    "            ys.extend(c[:,0,1])\n",
    "        fari_bottom_y.append(max(ys))\n",
    "    \n",
    "    y_base = max(fari_bottom_y)\n",
    "    x1 = extremes['SX'][0]\n",
    "    x2 = extremes['DX'][0]\n",
    "    y1 = min(y_base + 20, height-1)\n",
    "    y2 = min(y1 + int(0.18 * height), height)\n",
    "    \n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    if roi.size == 0:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    V_roi = hsv_roi[:,:,2]\n",
    "    \n",
    "    mask_plate = cv2.inRange(V_roi, config['V_PLATE_LOW'], config['V_PLATE_HIGH'])\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,3))\n",
    "    mask_plate = cv2.morphologyEx(mask_plate, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    contours,_ = cv2.findContours(mask_plate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    mask_cluster = np.zeros_like(mask_plate)\n",
    "    cv2.drawContours(mask_cluster, [largest], -1, 255, -1)\n",
    "    \n",
    "    ys, xs = np.where(mask_cluster > 0)\n",
    "    if len(xs) == 0 or len(ys) == 0:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    x_min, x_max = xs.min(), xs.max()\n",
    "    y_min, y_max = ys.min(), ys.max()\n",
    "    \n",
    "    pad_x = int(0.25 * (x_max - x_min))\n",
    "    pad_y = int(0.40 * (y_max - y_min))\n",
    "    \n",
    "    roi_x_min = max(0, x_min - pad_x)\n",
    "    roi_x_max = min(roi.shape[1], x_max + pad_x)\n",
    "    roi_y_min = max(0, y_min - pad_y)\n",
    "    roi_y_max = min(roi.shape[0], y_max + pad_y)\n",
    "    \n",
    "    roi_plate = roi[roi_y_min:roi_y_max, roi_x_min:roi_x_max]\n",
    "    \n",
    "    if roi_plate.size == 0:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    # Pre-processing\n",
    "    gray_plate = cv2.cvtColor(roi_plate, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    gray_plate = clahe.apply(gray_plate)\n",
    "    gray_plate = cv2.GaussianBlur(gray_plate, (7,7), 0)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    gradient = cv2.morphologyEx(gray_plate, cv2.MORPH_GRADIENT, kernel)\n",
    "    \n",
    "    _, gradient_binary = cv2.threshold(gradient, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Usa minAreaRect come fallback robusto\n",
    "    contours_grad, _ = cv2.findContours(gradient_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours_grad:\n",
    "        return False, None, None, None, None, None\n",
    "    \n",
    "    main_contour = max(contours_grad, key=cv2.contourArea)\n",
    "    \n",
    "    # minAreaRect (pi√π robusto)\n",
    "    rect = cv2.minAreaRect(main_contour)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int32(box)\n",
    "    \n",
    "    # Ordina punti (TL, TR, BR, BL)\n",
    "    pts = box.reshape(4,2)\n",
    "    s = pts.sum(axis=1)\n",
    "    d = np.diff(pts, axis=1).flatten()\n",
    "    \n",
    "    TL = tuple(pts[np.argmin(s)])\n",
    "    BR = tuple(pts[np.argmax(s)])\n",
    "    \n",
    "    remaining_idx = [i for i in range(4) if i not in [np.argmin(s), np.argmax(s)]]\n",
    "    if pts[remaining_idx[0]][0] > pts[remaining_idx[1]][0]:\n",
    "        TR = tuple(pts[remaining_idx[0]])\n",
    "        BL = tuple(pts[remaining_idx[1]])\n",
    "    else:\n",
    "        TR = tuple(pts[remaining_idx[1]])\n",
    "        BL = tuple(pts[remaining_idx[0]])\n",
    "    \n",
    "    plate_corners_roi = {'TL':TL,'TR':TR,'BL':BL,'BR':BR}\n",
    "    \n",
    "    # Converti in coordinate globali\n",
    "    plate_corners_global = {}\n",
    "    for k,(px,py) in plate_corners_roi.items():\n",
    "        plate_corners_global[k] = (px + roi_x_min + x1, py + roi_y_min + y1)\n",
    "    \n",
    "    # Backup points (centri lati)\n",
    "    backup_points = []\n",
    "    \n",
    "    debug_roi = None  # Placeholder\n",
    "    \n",
    "    return True, fari, extremes, plate_corners_global, backup_points, debug_roi\n",
    "\n",
    "\n",
    "print(\"‚úì Detection functions caricate\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TASK 1: HOMOGRAPHY SOLVER\n",
    "# =========================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def solve_with_homography(plate_corners, camera_matrix, vehicle_config):\n",
    "    \"\"\"\n",
    "    Task 1: Localizzazione usando omografia da 4 punti complanari (targa).\n",
    "    Formula: [r1 r2 t] = K‚Åª¬π H\n",
    "    \n",
    "    Args:\n",
    "        plate_corners: dict {'TL': (x,y), 'TR': (x,y), 'BL': (x,y), 'BR': (x,y)}\n",
    "        camera_matrix: matrice K (3x3)\n",
    "        vehicle_config: configurazione veicolo (coordinate 3D targa)\n",
    "    \n",
    "    Returns:\n",
    "        (rvec, tvec, method_info)\n",
    "    \"\"\"\n",
    "    # Punti 2D (immagine)\n",
    "    image_points = np.array([\n",
    "        plate_corners['TL'],\n",
    "        plate_corners['TR'],\n",
    "        plate_corners['BR'],\n",
    "        plate_corners['BL']\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Punti 3D (targa nel sistema del veicolo)\n",
    "    # Assumiamo targa su piano X=0 (posteriore)\n",
    "    plate_3d = vehicle_config['license_plate_rear_corners']\n",
    "    object_points = np.array([\n",
    "        plate_3d['top_left'][:2],      # Solo X, Y (Z = 0 per omografia)\n",
    "        plate_3d['top_right'][:2],\n",
    "        plate_3d['bottom_right'][:2],\n",
    "        plate_3d['bottom_left'][:2]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Calcola omografia H\n",
    "    H, status = cv2.findHomography(object_points, image_points, method=0)\n",
    "    \n",
    "    if H is None:\n",
    "        return None, None, {'error': 'Homography calculation failed'}\n",
    "    \n",
    "    # Decomposizione: [r1 r2 t] = K‚Åª¬π H\n",
    "    K_inv = np.linalg.inv(camera_matrix)\n",
    "    H_norm = K_inv @ H\n",
    "    \n",
    "    # Normalizzazione\n",
    "    lambda_ = (np.linalg.norm(H_norm[:, 0]) + np.linalg.norm(H_norm[:, 1])) / 2\n",
    "    H_norm = H_norm / lambda_\n",
    "    \n",
    "    # Estrai colonne\n",
    "    r1 = H_norm[:, 0]\n",
    "    r2 = H_norm[:, 1]\n",
    "    t = H_norm[:, 2]\n",
    "    \n",
    "    # Calcola r3 (perpendicolare al piano)\n",
    "    r3 = np.cross(r1, r2)\n",
    "    \n",
    "    # Costruisci matrice di rotazione\n",
    "    R = np.column_stack([r1, r2, r3])\n",
    "    \n",
    "    # Forza ortogonalit√† (SVD)\n",
    "    U, _, Vt = np.linalg.svd(R)\n",
    "    R = U @ Vt\n",
    "    \n",
    "    # Converti a Rodrigues\n",
    "    rvec, _ = cv2.Rodrigues(R)\n",
    "    tvec = t.reshape(3, 1)\n",
    "    \n",
    "    method_info = {\n",
    "        'name': 'Homography (Task 1)',\n",
    "        'points_used': 4,\n",
    "        'type': 'coplanar',\n",
    "        'lambda': float(lambda_)\n",
    "    }\n",
    "    \n",
    "    return rvec, tvec, method_info\n",
    "\n",
    "\n",
    "print(\"‚úì Task 1: Homography Solver caricato\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PNP FULL SOLVER (6+ punti)\n",
    "# =========================\n",
    "\n",
    "def solve_with_pnp_full(fari, plate_corners, camera_matrix, dist_coeffs, vehicle_config):\n",
    "    \"\"\"\n",
    "    Metodo completo con solvePnP usando tutti i punti disponibili.\n",
    "    \n",
    "    Args:\n",
    "        fari: [(x1,y1), (x2,y2)] centri fari\n",
    "        plate_corners: dict con 4 angoli targa\n",
    "        camera_matrix: K\n",
    "        dist_coeffs: coefficienti distorsione\n",
    "        vehicle_config: modello 3D veicolo\n",
    "    \n",
    "    Returns:\n",
    "        (rvec, tvec, method_info)\n",
    "    \"\"\"\n",
    "    # Punti 2D\n",
    "    image_points = []\n",
    "    object_points = []\n",
    "    \n",
    "    # Fari\n",
    "    tail_lights_3d = vehicle_config['tail_lights']\n",
    "    image_points.extend([fari[0], fari[1]])\n",
    "    object_points.extend([\n",
    "        tail_lights_3d['left'],\n",
    "        tail_lights_3d['right']\n",
    "    ])\n",
    "    \n",
    "    # Angoli targa\n",
    "    plate_3d = vehicle_config['license_plate_rear_corners']\n",
    "    for corner_2d_name, corner_3d_name in [\n",
    "        ('TL', 'top_left'), ('TR', 'top_right'), \n",
    "        ('BL', 'bottom_left'), ('BR', 'bottom_right')\n",
    "    ]:\n",
    "        if corner_2d_name in plate_corners:\n",
    "            image_points.append(plate_corners[corner_2d_name])\n",
    "            object_points.append(plate_3d[corner_3d_name])\n",
    "    \n",
    "    image_points = np.array(image_points, dtype=np.float32)\n",
    "    object_points = np.array(object_points, dtype=np.float32)\n",
    "    \n",
    "    # solvePnP\n",
    "    success, rvec, tvec = cv2.solvePnP(\n",
    "        object_points, \n",
    "        image_points, \n",
    "        camera_matrix, \n",
    "        dist_coeffs,\n",
    "        flags=cv2.SOLVEPNP_ITERATIVE\n",
    "    )\n",
    "    \n",
    "    if not success:\n",
    "        return None, None, {'error': 'PnP failed'}\n",
    "    \n",
    "    # Refine\n",
    "    rvec, tvec = cv2.solvePnPRefineLM(\n",
    "        object_points, \n",
    "        image_points, \n",
    "        camera_matrix, \n",
    "        dist_coeffs, \n",
    "        rvec, \n",
    "        tvec\n",
    "    )\n",
    "    \n",
    "    # Calcola errore di riproiezione\n",
    "    projected, _ = cv2.projectPoints(object_points, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "    projected = projected.reshape(-1, 2)\n",
    "    error = np.linalg.norm(image_points - projected, axis=1).mean()\n",
    "    \n",
    "    method_info = {\n",
    "        'name': 'PnP Full (6+ points)',\n",
    "        'points_used': len(image_points),\n",
    "        'type': 'over-determined',\n",
    "        'reprojection_error': float(error)\n",
    "    }\n",
    "    \n",
    "    return rvec, tvec, method_info\n",
    "\n",
    "\n",
    "print(\"‚úì PnP Full Solver caricato\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# BBOX 3D PROJECTOR\n",
    "# =========================\n",
    "\n",
    "def project_vehicle_bbox(rvec, tvec, camera_matrix, dist_coeffs, vehicle_config):\n",
    "    \"\"\"\n",
    "    Proietta la bounding box 3D del veicolo.\n",
    "    \n",
    "    Returns:\n",
    "        vertices_2d: array (8, 2) con vertici proiettati\n",
    "    \"\"\"\n",
    "    # Dimensioni veicolo\n",
    "    dims = vehicle_config['dimensions']\n",
    "    L = dims['length']\n",
    "    W = dims['width']\n",
    "    H = dims['height']\n",
    "    \n",
    "    # 8 vertici della bbox (origine: centro asse posteriore a suolo)\n",
    "    vertices_3d = np.array([\n",
    "        # Base (z=0)\n",
    "        [0, -W/2, 0],      # 0: posteriore-destra\n",
    "        [0, W/2, 0],       # 1: posteriore-sinistra\n",
    "        [L, W/2, 0],       # 2: anteriore-sinistra\n",
    "        [L, -W/2, 0],      # 3: anteriore-destra\n",
    "        # Top (z=H)\n",
    "        [0, -W/2, H],      # 4: posteriore-destra top\n",
    "        [0, W/2, H],       # 5: posteriore-sinistra top\n",
    "        [L, W/2, H],       # 6: anteriore-sinistra top\n",
    "        [L, -W/2, H]       # 7: anteriore-destra top\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # Proietta\n",
    "    vertices_2d, _ = cv2.projectPoints(vertices_3d, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "    return vertices_2d.reshape(-1, 2).astype(int)\n",
    "\n",
    "\n",
    "def draw_bbox_3d(frame, vertices_2d, color=(0, 255, 0), thickness=2):\n",
    "    \"\"\"\n",
    "    Disegna la bbox 3D sul frame.\n",
    "    \"\"\"\n",
    "    frame_copy = frame.copy()\n",
    "    \n",
    "    # Edges base (0-1-2-3-0)\n",
    "    base_edges = [(0,1), (1,2), (2,3), (3,0)]\n",
    "    for i, j in base_edges:\n",
    "        cv2.line(frame_copy, tuple(vertices_2d[i]), tuple(vertices_2d[j]), color, thickness)\n",
    "    \n",
    "    # Edges top (4-5-6-7-4)\n",
    "    top_edges = [(4,5), (5,6), (6,7), (7,4)]\n",
    "    for i, j in top_edges:\n",
    "        cv2.line(frame_copy, tuple(vertices_2d[i]), tuple(vertices_2d[j]), color, thickness)\n",
    "    \n",
    "    # Vertical edges (0-4, 1-5, 2-6, 3-7)\n",
    "    for i in range(4):\n",
    "        cv2.line(frame_copy, tuple(vertices_2d[i]), tuple(vertices_2d[i+4]), color, thickness)\n",
    "    \n",
    "    # Evidenzia posteriore (rosso)\n",
    "    cv2.line(frame_copy, tuple(vertices_2d[0]), tuple(vertices_2d[1]), (0, 0, 255), thickness+1)\n",
    "    cv2.line(frame_copy, tuple(vertices_2d[4]), tuple(vertices_2d[5]), (0, 0, 255), thickness+1)\n",
    "    \n",
    "    return frame_copy\n",
    "\n",
    "\n",
    "print(\"‚úì BBox 3D Projector caricato\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# VEHICLE CONFIGURATION\n",
    "# =========================\n",
    "\n",
    "VEHICLE_CONFIG = {\n",
    "    'dimensions': {\n",
    "        'length': 3.70,\n",
    "        'width': 1.74,\n",
    "        'height': 1.525\n",
    "    },\n",
    "    'tail_lights': {\n",
    "        'left': np.array([-0.27, 0.70, 0.50]),\n",
    "        'right': np.array([-0.27, -0.70, 0.50])\n",
    "    },\n",
    "    'license_plate_rear_corners': {\n",
    "        'top_left': np.array([0.0, 0.26, 0.455]),\n",
    "        'top_right': np.array([0.0, -0.26, 0.455]),\n",
    "        'bottom_left': np.array([0.0, 0.26, 0.345]),\n",
    "        'bottom_right': np.array([0.0, -0.26, 0.345])\n",
    "    }\n",
    "}\n",
    "\n",
    "# Camera (MODIFICA CON I TUOI PARAMETRI)\n",
    "CAMERA_MATRIX = np.array([\n",
    "    [800.0, 0, 640.0],\n",
    "    [0, 800.0, 360.0],\n",
    "    [0, 0, 1]\n",
    "], dtype=np.float64)\n",
    "\n",
    "DIST_COEFFS = np.zeros(5, dtype=np.float64)\n",
    "\n",
    "print(\"‚úì Configurazione veicolo e camera caricata\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN SYSTEM CON AUTO-TRIGGER\n",
    "# =========================\n",
    "\n",
    "def detect_vehicle_presence(frame, config, min_red_area_ratio=0.001):\n",
    "    \"\"\"\n",
    "    Verifica se c'√® un veicolo nel frame controllando la presenza di luci rosse.\n",
    "    \n",
    "    Args:\n",
    "        frame: Frame BGR\n",
    "        config: Configurazione detection\n",
    "        min_red_area_ratio: Percentuale minima di pixel rossi luminosi (default 0.1%)\n",
    "    \n",
    "    Returns:\n",
    "        (is_present, red_pixel_count, confidence)\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    total_pixels = width * height\n",
    "    \n",
    "    # Estrai canale V (luminosit√†)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    V = hsv[:, :, 2]\n",
    "    \n",
    "    # Maschera per zone luminose rosse (fari posteriori)\n",
    "    mask_bright = cv2.inRange(V, config['V_LOWER'], 255)\n",
    "    \n",
    "    # Conta pixel luminosi\n",
    "    bright_pixels = np.sum(mask_bright > 0)\n",
    "    bright_ratio = bright_pixels / total_pixels\n",
    "    \n",
    "    # Soglia: almeno 0.1% del frame √® luminoso\n",
    "    min_pixels = int(total_pixels * min_red_area_ratio)\n",
    "    is_present = bright_pixels > min_pixels\n",
    "    \n",
    "    # Confidence basata su quanta area luminosa c'√®\n",
    "    confidence = min(bright_ratio / (min_red_area_ratio * 3), 1.0)\n",
    "    \n",
    "    return is_present, bright_pixels, confidence\n",
    "\n",
    "\n",
    "def wait_for_vehicle(cap, config, max_frames_to_check=300, visualize=True):\n",
    "    \"\"\"\n",
    "    Scansiona il video fino a trovare il veicolo.\n",
    "    \n",
    "    Args:\n",
    "        cap: VideoCapture object\n",
    "        config: Configurazione detection\n",
    "        max_frames_to_check: Massimo numero di frame da controllare\n",
    "        visualize: Se True, mostra il progresso\n",
    "    \n",
    "    Returns:\n",
    "        (frame_idx, frame, detection_data) o (None, None, None) se non trovato\n",
    "    \"\"\"\n",
    "    print(\"\\nüîç RICERCA VEICOLO NEL VIDEO...\")\n",
    "    print(f\"   Scansione primi {max_frames_to_check} frames...\")\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    \n",
    "    for frame_idx in range(max_frames_to_check):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Check presenza veicolo\n",
    "        is_present, red_pixels, confidence = detect_vehicle_presence(frame, config)\n",
    "        \n",
    "        if visualize and frame_idx % 30 == 0:\n",
    "            print(f\"  Frame {frame_idx}: pixels rossi={red_pixels}, confidence={confidence:.2%}\")\n",
    "        \n",
    "        # Se troviamo presenza significativa, verifica con detection completa\n",
    "        if is_present and confidence > 0.3:\n",
    "            print(f\"\\n‚úì Possibile veicolo rilevato al frame {frame_idx}\")\n",
    "            print(f\"   Confidence: {confidence:.2%}, Pixel rossi: {red_pixels}\")\n",
    "            \n",
    "            # Tenta detection completa\n",
    "            success, fari, extremes, plate_corners, backup_points, _ = detect_headlights_and_plate(frame, config)\n",
    "            \n",
    "            if success:\n",
    "                print(f\"‚úÖ VEICOLO CONFERMATO al frame {frame_idx}!\")\n",
    "                print(f\"   Fari: {len(fari)} rilevati\")\n",
    "                print(f\"   Angoli targa: {len(plate_corners)}\")\n",
    "                \n",
    "                detection_data = {\n",
    "                    'fari': fari,\n",
    "                    'extremes': extremes,\n",
    "                    'plate_corners': plate_corners,\n",
    "                    'backup_points': backup_points\n",
    "                }\n",
    "                \n",
    "                return frame_idx, frame, detection_data\n",
    "            else:\n",
    "                print(f\"   Detection completa fallita, continuo ricerca...\")\n",
    "    \n",
    "    print(f\"\\n‚ùå Nessun veicolo trovato nei primi {max_frames_to_check} frames\")\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def process_video_with_method(video_path, method_choice, config):\n",
    "    \"\"\"\n",
    "    Processa video con il metodo scelto.\n",
    "    Versione migliorata con auto-trigger su comparsa veicolo.\n",
    "    \"\"\"\n",
    "    # Nome metodo\n",
    "    method_names = {\n",
    "        1: 'homography',\n",
    "        2: 'pnp_full'\n",
    "    }\n",
    "    method_name = method_names[method_choice]\n",
    "    \n",
    "    # Output path\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    output_path = os.path.join(\n",
    "        os.path.dirname(video_path).replace('input', 'output'),\n",
    "        f\"{video_name}_{method_name}_3d.mp4\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüé¨ PROCESSING CON METODO: {method_name.upper()}\")\n",
    "    print(f\"üìπ Input: {video_path}\")\n",
    "    print(f\"üíæ Output: {output_path}\")\n",
    "    \n",
    "    # Apri video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"\\nüìä Info video:\")\n",
    "    print(f\"   Risoluzione: {width}x{height}\")\n",
    "    print(f\"   FPS: {fps}\")\n",
    "    print(f\"   Frames totali: {total_frames}\")\n",
    "    \n",
    "    # === AUTO-TRIGGER: Attendi veicolo ===\n",
    "    start_frame, first_frame, detection_data = wait_for_vehicle(cap, config, max_frames_to_check=300)\n",
    "    \n",
    "    if start_frame is None:\n",
    "        print(\"\\n‚ùå ERRORE: Veicolo non rilevato nel video!\")\n",
    "        print(\"   Suggerimenti:\")\n",
    "        print(\"   - Verifica che ci sia un veicolo con fari accesi\")\n",
    "        print(\"   - Controlla i parametri V_LOWER in config\")\n",
    "        print(\"   - Prova ad aumentare max_frames_to_check\")\n",
    "        cap.release()\n",
    "        return\n",
    "    \n",
    "    fari = detection_data['fari']\n",
    "    extremes = detection_data['extremes']\n",
    "    plate_corners = detection_data['plate_corners']\n",
    "    backup_points = detection_data['backup_points']\n",
    "    \n",
    "    # === Setup output video ===\n",
    "    # Crea directory output se non esiste\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # === Scrivi frames precedenti (senza bbox) ===\n",
    "    print(f\"\\nüìù Scrittura frames iniziali ({start_frame} frames)...\")\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    for i in range(start_frame):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Aggiungi solo info base\n",
    "        overlay = frame.copy()\n",
    "        cv2.putText(overlay, f\"Frame: {i}/{total_frames}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "        cv2.putText(overlay, \"WAITING FOR VEHICLE...\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "        out.write(overlay)\n",
    "    \n",
    "    # === Processing con tracking ===\n",
    "    print(f\"\\n‚è≥ PROCESSING dal frame {start_frame} al frame {total_frames}...\")\n",
    "    \n",
    "    # Tracking setup\n",
    "    prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    tracked_points = {\n",
    "        'faro_sx': np.array([fari[0]], dtype=np.float32),\n",
    "        'faro_dx': np.array([fari[1]], dtype=np.float32),\n",
    "    }\n",
    "    for corner, pt in plate_corners.items():\n",
    "        tracked_points[f'plate_{corner}'] = np.array([pt], dtype=np.float32)\n",
    "    \n",
    "    lk_params = dict(winSize=(21, 21), maxLevel=3,\n",
    "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "    \n",
    "    frames_processed = start_frame\n",
    "    frames_with_pose = 0\n",
    "    redetection_interval = 30\n",
    "    frames_since_redetection = 0\n",
    "    \n",
    "    while frames_processed < total_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        overlay = frame.copy()\n",
    "        curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # === TRACKING OPTICAL FLOW ===\n",
    "        new_tracked = {}\n",
    "        for name, pts in tracked_points.items():\n",
    "            new_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, pts, None, **lk_params)\n",
    "            if status[0][0] == 1:\n",
    "                new_tracked[name] = new_pts\n",
    "        \n",
    "        tracked_points = new_tracked\n",
    "        \n",
    "        # Ricostruisci dati\n",
    "        fari = []\n",
    "        plate_corners = {}\n",
    "        \n",
    "        if 'faro_sx' in tracked_points:\n",
    "            fari.append(tuple(tracked_points['faro_sx'][0].astype(int)))\n",
    "        if 'faro_dx' in tracked_points:\n",
    "            fari.append(tuple(tracked_points['faro_dx'][0].astype(int)))\n",
    "        \n",
    "        for corner in ['TL', 'TR', 'BL', 'BR']:\n",
    "            key = f'plate_{corner}'\n",
    "            if key in tracked_points:\n",
    "                plate_corners[corner] = tuple(tracked_points[key][0].astype(int))\n",
    "        \n",
    "        # === RE-DETECTION PERIODICA ===\n",
    "        frames_since_redetection += 1\n",
    "        if frames_since_redetection >= redetection_interval:\n",
    "            success, new_fari, new_extremes, new_plate, new_backup, _ = detect_headlights_and_plate(frame, config)\n",
    "            if success:\n",
    "                # Reinizializza tracking\n",
    "                fari = new_fari\n",
    "                plate_corners = new_plate\n",
    "                tracked_points = {\n",
    "                    'faro_sx': np.array([fari[0]], dtype=np.float32),\n",
    "                    'faro_dx': np.array([fari[1]], dtype=np.float32),\n",
    "                }\n",
    "                for corner, pt in plate_corners.items():\n",
    "                    tracked_points[f'plate_{corner}'] = np.array([pt], dtype=np.float32)\n",
    "                \n",
    "                frames_since_redetection = 0\n",
    "                \n",
    "                cv2.putText(overlay, \"RE-DETECTION OK\", (10, 90),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        \n",
    "        # === CALCOLA POSA ===\n",
    "        rvec, tvec, method_info = None, None, None\n",
    "        \n",
    "        if method_choice == 1:  # Homography\n",
    "            if len(plate_corners) == 4:\n",
    "                rvec, tvec, method_info = solve_with_homography(\n",
    "                    plate_corners, CAMERA_MATRIX, VEHICLE_CONFIG\n",
    "                )\n",
    "        \n",
    "        elif method_choice == 2:  # PnP Full\n",
    "            if len(fari) == 2 and len(plate_corners) >= 3:\n",
    "                rvec, tvec, method_info = solve_with_pnp_full(\n",
    "                    fari, plate_corners, CAMERA_MATRIX, DIST_COEFFS, VEHICLE_CONFIG\n",
    "                )\n",
    "        \n",
    "        # === VISUALIZZA BBOX 3D ===\n",
    "        if rvec is not None and tvec is not None:\n",
    "            vertices_2d = project_vehicle_bbox(rvec, tvec, CAMERA_MATRIX, DIST_COEFFS, VEHICLE_CONFIG)\n",
    "            overlay = draw_bbox_3d(overlay, vertices_2d)\n",
    "            frames_with_pose += 1\n",
    "            \n",
    "            # Info posa\n",
    "            distance = np.linalg.norm(tvec)\n",
    "            cv2.putText(overlay, f\"Distance: {distance:.2f}m\", (10, height - 60),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        # === VISUALIZZA PUNTI ===\n",
    "        for i, pt in enumerate(fari):\n",
    "            cv2.circle(overlay, pt, 8, (0, 255, 255), -1)\n",
    "            cv2.putText(overlay, 'L' if i == 0 else 'R', (pt[0]+10, pt[1]),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        \n",
    "        if len(plate_corners) == 4:\n",
    "            poly = np.array([\n",
    "                plate_corners['TL'], plate_corners['TR'],\n",
    "                plate_corners['BR'], plate_corners['BL']\n",
    "            ], dtype=np.int32)\n",
    "            cv2.polylines(overlay, [poly], True, (0, 255, 0), 2)\n",
    "        \n",
    "        # === INFO ===\n",
    "        cv2.putText(overlay, f\"Frame: {frames_processed}/{total_frames}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(overlay, f\"Method: {method_info['name'] if method_info else 'N/A'}\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        # Indicatore re-detection\n",
    "        next_redetect = redetection_interval - frames_since_redetection\n",
    "        color = (0, 255, 255) if next_redetect <= 3 else (200, 200, 200)\n",
    "        cv2.putText(overlay, f\"Next detect: {next_redetect}\", (10, height - 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        out.write(overlay)\n",
    "        frames_processed += 1\n",
    "        prev_gray = curr_gray.copy()\n",
    "        \n",
    "        if frames_processed % 50 == 0:\n",
    "            progress = (frames_processed - start_frame) / (total_frames - start_frame) * 100\n",
    "            print(f\"  üìç {frames_processed}/{total_frames} ({progress:.1f}%) - Pose: {frames_with_pose}\")\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # === SUMMARY ===\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"‚úÖ PROCESSING COMPLETATO!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"üìä Statistiche:\")\n",
    "    print(f\"   Frame iniziale veicolo: {start_frame}\")\n",
    "    print(f\"   Frames processati: {frames_processed - start_frame}\")\n",
    "    print(f\"   Frames con posa 3D: {frames_with_pose}\")\n",
    "    if frames_processed > start_frame:\n",
    "        success_rate = frames_with_pose / (frames_processed - start_frame) * 100\n",
    "        print(f\"   Tasso successo: {success_rate:.1f}%\")\n",
    "    print(f\"\\nüíæ Video salvato: {output_path}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "\n",
    "print(\"‚úì Sistema main con auto-trigger caricato\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## =========================\n",
    "# ESECUZIONE\n",
    "# =========================\n",
    "\n",
    "# Configurazione detection\n",
    "config = {\n",
    "    'V_LOWER': 210,\n",
    "    'MAX_Y_RATIO': 0.80,\n",
    "    'MIN_VERTICAL_RATIO': 1.2,\n",
    "    'MIN_CONTOUR_AREA_RATIO': 0.00015,\n",
    "    'Y_TOLERANCE': 5,\n",
    "    'V_PLATE_LOW': 150,\n",
    "    'V_PLATE_HIGH': 240,\n",
    "}\n",
    "\n",
    "# Trova video\n",
    "VIDEO_DIR = '/app/data/videos/input/'\n",
    "videos = [f for f in os.listdir(VIDEO_DIR) if f.endswith(('.mp4','.avi','.mov'))]\n",
    "\n",
    "if not videos:\n",
    "    print(\"‚ùå Nessun video trovato!\")\n",
    "else:\n",
    "    VIDEO_PATH = os.path.join(VIDEO_DIR, videos[0])\n",
    "    print(f\"üìπ Video selezionato: {videos[0]}\")\n",
    "    \n",
    "    # MENU INTERATTIVO\n",
    "    method_choice = show_method_menu()\n",
    "    \n",
    "    # PROCESSA\n",
    "    process_video_with_method(VIDEO_PATH, method_choice, config)\n",
    "# ```\n",
    "\n",
    "#---\n",
    "\n",
    "## üéØ **Come Usare**\n",
    "\n",
    "# 1. **Esegui tutte le celle** in ordine (1-6)\n",
    "# 2. Alla **Cella 6** apparir√† il menu:\n",
    "# ```\n",
    "# ==============================================================\n",
    "# VEHICLE 3D LOCALIZATION - METODO DI CALCOLO\n",
    "# ==============================================================\n",
    "\n",
    "# Scegli il metodo di localizzazione:\n",
    "\n",
    "# 1. HOMOGRAPHY (Task 1)\n",
    "#   - Usa 4 angoli targa (complanari)\n",
    "#   - Formula: [r1 r2 t] = K‚Åª¬π H\n",
    "#   - Limitazione: scarsa prospettiva\n",
    "\n",
    "#2. PNP FULL (Metodo Completo)\n",
    "#   - Usa 6+ punti (fari + targa)\n",
    "#   - solvePnP con refinement\n",
    "#   - Pi√π robusto e accurato\n",
    "\n",
    "#==============================================================\n",
    "\n",
    "# Inserisci scelta (1-2):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
